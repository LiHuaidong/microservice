2018-11-13 11:55:08  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 11:55:08  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 11:55:08  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 11:55:29  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:55:50  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:56:12  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:56:33  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:56:54  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:57:16  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:57:38  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:58:00  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:58:22  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:58:44  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:59:06  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:59:28  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 11:59:50  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:00:12  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:00:34  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:00:56  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:01:18  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:01:40  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:02:03  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:02:24  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:02:47  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:03:09  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:03:31  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:03:53  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:04:15  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:04:37  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 12:04:59  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 15:46:32  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 15:46:32  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 15:46:32  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 15:46:53  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:38:37  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 17:38:37  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 17:38:37  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 17:39:04  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:39:25  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:39:52  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:40:13  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:40:35  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:40:57  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:41:19  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:41:41  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:42:03  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:42:25  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:42:47  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:43:09  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:43:31  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:43:53  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:44:15  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:44:37  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:44:59  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:45:21  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:45:43  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:46:05  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:46:27  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:46:49  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:47:11  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:47:33  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:47:55  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:48:17  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:48:39  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:49:01  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:49:23  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:49:45  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:50:07  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:50:29  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:50:52  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:51:14  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:51:35  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:51:57  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:52:19  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:52:41  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:53:03  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:53:25  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:53:47  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:54:09  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:54:31  WARN org.apache.kafka.clients.NetworkClient.processDisconnection(NetworkClient.java:671) - [Producer clientId=producer-1] Connection to node -1 could not be established. Broker may not be available.
2018-11-13 17:54:41  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 17:54:41  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 17:54:45  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 17:54:45  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 17:54:45  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 17:54:45  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 17:54:45  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 17:54:59  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 17:54:59  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 17:54:59  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 17:54:59  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 17:54:59  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 17:55:08  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 17:55:08  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 17:55:08  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 17:55:09  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 17:55:09  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 17:55:31  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 17:55:31  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 17:55:31  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 17:55:35  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:02:01  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [elasticsearch:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-11-13 18:02:01  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:02:01  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:02:01  WARN org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse(NetworkClient.java:968) - [Consumer clientId=consumer-1, groupId=test] Error while fetching metadata with correlation id 2 : {mr-yang=LEADER_NOT_AVAILABLE}
2018-11-13 18:02:01  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:02:01  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:677) - [Consumer clientId=consumer-1, groupId=test] Discovered group coordinator elasticsearch:9092 (id: 2147483647 rack: null)
2018-11-13 18:02:01  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:462) - [Consumer clientId=consumer-1, groupId=test] Revoking previously assigned partitions []
2018-11-13 18:02:01  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest(AbstractCoordinator.java:509) - [Consumer clientId=consumer-1, groupId=test] (Re-)joining group
2018-11-13 18:02:01  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1.onSuccess(AbstractCoordinator.java:473) - [Consumer clientId=consumer-1, groupId=test] Successfully joined group with generation 1
2018-11-13 18:02:01  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:280) - [Consumer clientId=consumer-1, groupId=test] Setting newly assigned partitions [mr-yang-0]
2018-11-13 18:02:01  INFO org.apache.kafka.clients.consumer.internals.Fetcher.resetOffsetIfNeeded(Fetcher.java:583) - [Consumer clientId=consumer-1, groupId=test] Resetting offset for partition mr-yang-0 to offset 0.
2018-11-13 18:03:44  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 18:04:06  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 18:04:06  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:04:06  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:04:06  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:04:06  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 18:04:24  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 18:04:24  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:04:24  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:04:24  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:04:24  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-11-13 18:09:54  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [elasticsearch:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-11-13 18:09:54  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:09:54  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:09:54  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:09:54  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:677) - [Consumer clientId=consumer-1, groupId=test] Discovered group coordinator elasticsearch:9092 (id: 2147483647 rack: null)
2018-11-13 18:09:54  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:462) - [Consumer clientId=consumer-1, groupId=test] Revoking previously assigned partitions []
2018-11-13 18:09:54  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest(AbstractCoordinator.java:509) - [Consumer clientId=consumer-1, groupId=test] (Re-)joining group
2018-11-13 18:09:54  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1.onSuccess(AbstractCoordinator.java:473) - [Consumer clientId=consumer-1, groupId=test] Successfully joined group with generation 3
2018-11-13 18:09:54  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:280) - [Consumer clientId=consumer-1, groupId=test] Setting newly assigned partitions [mr-yang-0]
2018-11-13 18:11:14  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [elasticsearch:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-11-13 18:11:14  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:11:14  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:11:14  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:11:14  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:677) - [Consumer clientId=consumer-1, groupId=test] Discovered group coordinator elasticsearch:9092 (id: 2147483647 rack: null)
2018-11-13 18:11:14  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:462) - [Consumer clientId=consumer-1, groupId=test] Revoking previously assigned partitions []
2018-11-13 18:11:14  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest(AbstractCoordinator.java:509) - [Consumer clientId=consumer-1, groupId=test] (Re-)joining group
2018-11-13 18:11:28  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1.onSuccess(AbstractCoordinator.java:473) - [Consumer clientId=consumer-1, groupId=test] Successfully joined group with generation 5
2018-11-13 18:11:28  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:280) - [Consumer clientId=consumer-1, groupId=test] Setting newly assigned partitions [mr-yang-0]
2018-11-13 18:13:38  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [elasticsearch:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-topic
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-11-13 18:13:38  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:13:38  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:13:38  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:13:38  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:677) - [Consumer clientId=consumer-1, groupId=test-topic] Discovered group coordinator elasticsearch:9092 (id: 2147483647 rack: null)
2018-11-13 18:13:38  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:462) - [Consumer clientId=consumer-1, groupId=test-topic] Revoking previously assigned partitions []
2018-11-13 18:13:38  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest(AbstractCoordinator.java:509) - [Consumer clientId=consumer-1, groupId=test-topic] (Re-)joining group
2018-11-13 18:13:39  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1.onSuccess(AbstractCoordinator.java:473) - [Consumer clientId=consumer-1, groupId=test-topic] Successfully joined group with generation 1
2018-11-13 18:13:39  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:280) - [Consumer clientId=consumer-1, groupId=test-topic] Setting newly assigned partitions [mr-yang-0]
2018-11-13 18:13:39  INFO org.apache.kafka.clients.consumer.internals.Fetcher.resetOffsetIfNeeded(Fetcher.java:583) - [Consumer clientId=consumer-1, groupId=test-topic] Resetting offset for partition mr-yang-0 to offset 0.
2018-11-13 18:16:13  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [elasticsearch:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-11-13 18:16:13  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:16:13  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:16:13  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:16:13  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:677) - [Consumer clientId=consumer-1, groupId=test] Discovered group coordinator elasticsearch:9092 (id: 2147483647 rack: null)
2018-11-13 18:16:13  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:462) - [Consumer clientId=consumer-1, groupId=test] Revoking previously assigned partitions []
2018-11-13 18:16:13  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest(AbstractCoordinator.java:509) - [Consumer clientId=consumer-1, groupId=test] (Re-)joining group
2018-11-13 18:16:13  INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1.onSuccess(AbstractCoordinator.java:473) - [Consumer clientId=consumer-1, groupId=test] Successfully joined group with generation 7
2018-11-13 18:16:13  INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:280) - [Consumer clientId=consumer-1, groupId=test] Setting newly assigned partitions [test-topic-0]
2018-11-13 18:16:13  INFO org.apache.kafka.clients.consumer.internals.Fetcher.resetOffsetIfNeeded(Fetcher.java:583) - [Consumer clientId=consumer-1, groupId=test] Resetting offset for partition test-topic-0 to offset 596.
2018-11-13 18:18:24  INFO org.apache.kafka.common.config.AbstractConfig.logAll(AbstractConfig.java:279) - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [elasticsearch:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-11-13 18:18:25  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:109) - Kafka version : 2.0.0
2018-11-13 18:18:25  INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo.<init>(AppInfoParser.java:110) - Kafka commitId : 3402a8361b734732
2018-11-13 18:18:25  INFO org.apache.kafka.clients.Metadata.update(Metadata.java:273) - Cluster ID: VbXF_w1HSjCaCOXzdlZvWg
2018-11-13 18:18:25  INFO org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1090) - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
